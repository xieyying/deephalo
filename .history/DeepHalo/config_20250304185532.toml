# This file is a configuration file used to set parameters for DeepHalo.

# Parameters for the analyze-mzml subcommand.

[FeatureFinding]
mass_trace_detection = [
    ["mass_error_ppm", 10.0], # Precursor mass error in ppm (default: 20.0; adjust based on experimental conditions)
    ["min_trace_length", 1.0], # Minimum trace length (default: 5.0; adjust based on experimental conditions)
    ["noise_threshold_int", 200.0], # Noise intensity threshold (adjust based on experimental conditions)
    ["chrom_peak_snr", 10.0], # Chromatographic peak signal-to-noise ratio (adjust based on experimental conditions)
    ["trace_termination_criterion", "outlier"],
    ["trace_termination_outliers", 5],
    ["min_sample_rate", 0.5],
    ["quant_method", "area"],
    ["reestimate_mt_sd", "true"],
    ["max_trace_length", -1.0],
]

elution_peak_detection = [
    ["chrom_fwhm", 3.0], # Chromatographic full width at half maximum (default: 5.0)
    ["chrom_peak_snr", 3.0],
    ["width_filtering", "auto"],
    ["min_fwhm", 1.0],
    ["max_fwhm", 60.0],
    ["masstrace_snr_filtering", "false"],
]

feature_detection = [
    ["local_rt_range", 10.0],
    ["local_mz_range", 6.5], # Local m/z range (default: 6.5; adjust if necessary — e.g., DeepHalo uses 5 isotope peaks, so you may set to 5.5)
    ["chrom_fwhm", 3.0], # Chromatographic full width at half maximum (default: 5.0; adjust based on experimental conditions)
    ["report_summed_ints", "false"],
    ["mz_scoring_13C", "false"],
    ["charge_lower_bound", 1],
    ["charge_upper_bound", 1],
    ["enable_RT_filtering", "true"],
    ["use_smoothed_intensities", "true"],
    ["mz_scoring_by_elements", "true"], # Required for DeepHalo (not default in pyopenms)
    ["elements", "CHNOPSFClBrINaFeSeB"],
    ["report_chromatograms", "false"],
    ["isotope_filtering_model", "none"], # Required for DeepHalo (not default in pyopenms)
    ["remove_single_traces", "true"], # Remove single traces; required for DeepHalo (not default in pyopenms)
    ["report_convex_hulls", "true"] # Report convex hulls; required for DeepHalo (not default in pyopenms)
]

## feature_grouping parameters and comments inherited from pyopenms
feature_grouping = [['mz_unit', 'ppm'], # Unit of m/z tolerance
                    ['nr_partitions', 1000], # Number of partitions in m/z space
                    ['warp:enabled', 'true'],  # Whether or not to internally warp feature RTs using LOWESS transformation before linking (reported RTs in results will always be the original RTs)
                    ['warp:rt_tol', 100.0],  # Width of RT tolerance window (sec)
                    ['warp:mz_tol', 20.0], # m/z tolerance (in ppm or Da) default is 5.0
                    ['warp:max_pairwise_log_fc', 2.0], # default: 0.5, Maximum absolute log10 fold change between two compatible signals during compatibility graph construction. Two signals from different maps will not be connected by an edge in the compatibility graph if absolute log fold change exceeds this limit (they might still end up in the same connected component, however). Note: this does not limit fold changes in the linking stage, only during RT alignment, where we try to find high-quality alignment anchor points. Setting this to a value < 0 disables the FC check.
                    ['warp:min_rel_cc_size', 0.01], # Only connected components containing compatible features from at least max(2, (warp_min_occur * number_of_input_maps)) input maps are considered for computing the warping function
                    ['warp:max_nr_conflicts', 0], # Allow up to this many conflicts (features from the same map) per connected component to be used for alignment (-1 means allow any number of conflicts)
                    ['link:rt_tol', 200.0], # Width of RT tolerance window (sec)
                    ['link:mz_tol', 20.0], # m/z tolerance (in ppm or Da)
                    ['link:charge_merging', 'With_charge_zero'], # whether to disallow charge mismatches (Identical), allow to link charge zero (i.e., unknown charge state) with every charge state, or disregard charges (Any)
                    ['link:adduct_merging', 'Any'], # whether to only allow the same adduct for linking (Identical), also allow linking features with adduct-free ones, or disregard adducts (Any)
                    ['distance_RT:exponent', 1.0], # Normalized RT differences ([0-1], relative to 'max_difference') are raised to this power (using 1 or 2 will be fast, everything else is REALLY slow)
                    ['distance_RT:weight', 1.0], # Final RT distances are weighted by this factor
                    ['distance_MZ:exponent', 2.0], # Normalized ([0-1], relative to 'max_difference') m/z differences are raised to this power (using 1 or 2 will be fast, everything else is REALLY slow)
                    ['distance_MZ:weight', 1.0], # Final m/z distances are weighted by this factor
                    ['distance_intensity:exponent', 1.0], # Differences in relative intensity ([0-1]) are raised to this power (using 1 or 2 will be fast, everything else is REALLY slow)
                    ['distance_intensity:weight', 1.0], # Final intensity distances are weighted by this factor
                    ['distance_intensity:log_transform', 'enabled'], # Log-transform intensities? If disabled, d = |int_f2 - int_f1| / int_max. If enabled, d = |log(int_f2 + 1) - log(int_f1 + 1)| / log(int_max + 1))
                    ['LOWESS:span', 0.6666666666666666], # Fraction of datapoints (f) to use for each local regression (determines the amount of smoothing). Choosing this parameter in the range .2 to .8 usually results in a good fit.
                    ['LOWESS:num_iterations', 3], # Number of robustifying iterations for lowess fitting.
                    ['LOWESS:delta', -1.0], # Nonnegative parameter which may be used to save computations (recommended value is 0.01 of the range of the input, e.g. for data ranging from 1000 seconds to 2000 seconds, it could be set to 10). Setting a negative value will automatically do this.
                    ['LOWESS:interpolation_type', 'cspline'], # Method to use for interpolation between datapoints computed by lowess. 'linear': Linear interpolation. 'cspline': Use the cubic spline for interpolation. 'akima': Use an akima spline for interpolation
                    ['LOWESS:extrapolation_type', 'four-point-linear'] # Method to use for extrapolation outside the data range. 'two-point-linear': Uses a line through the first and last point to extrapolate. 'four-point-linear': Uses a line through the first and second point to extrapolate in front and and a line through the last and second-to-last point in the end. 'global-linear': Uses a linear regression to fit a line through all data points and use it for interpolation.
                    ]
# For details on the above parameters, please refer to pyopenms.

[FeatureMapProcessor]
min_num_of_masstraces = 3 # Halogenated compounds should have at least 3 isotope peaks
min_feature_int = 10000  # Minimum feature intensity for further analysis of halogenated compounds (sum intensity of a candidate feature).
min_scan_number = 3       # Minimum number of scans required.
use_mass_difference = ''  # Set to 'none' to disable mass difference correction for isotope patterns, or leave empty ('') to enable it.

[FeatureFilter]
H_score_threshold = 0 # Range: 0-1. Higher values indicate higher confidence.
Anomaly_detection_threshold = 7.015356328085893e-05  # Isotope peak intensity reconstruction error from ADM.
                                                     # Recommended range: [7.015356328085893e-05, 1].
                                                     # Use 7.015356328085893e-05 to apply filtering, or 1.0 to disable filtering.

# Parameters for the dereplication subcommand
[Dereplication]
error_ppm = 10 # Precursor mass tolerance in ppm
Inty_cosine_score = 0.96 # Minimum cosine score threshold between experimental and theoretical intensities

# Parameters for the create-dataset subcommand
[datasets]
paths = [
        ["E:/XinBackup/Lab/深度学习相关/数据_public/NPAtlas_download.csv",
        "compound_molecular_formula",
     ],      
]

# Database file path
# type_list = ['base','Fe','B','Se','hydro']
# type_list = ['base']
type_list = ['Fe','B','Se','hydro']

element_list = ['C','H','O','N','F', 'P', 'S', 'Cl', 'Br','I','Na','B', 'Fe', 'Se']
# element_list = ['C','H','O','N']  # Elements included in the training set
mz_start = 50           # Starting m/z value
mz_end = 2000           # Ending m/z value
rate_for_hydro = [0.33, 0.66, 0.99, 1.32, 1.65, 2.3, 5]  # Rates used for simulating hydro
return_from_max_ints = "True"  # Whether to start returning from the peak with the maximum intensity

# Parameters for the create-model subcommand
[model_data]

# Feature list used for training
feature_list = [
    "p0_int",
    "p1_int",
    "p2_int",
    "p3_int",
    "p4_int",
    "m2_m1",
    "m1_m0",
]

# Datasets used for training
use_add_fe_data = "True"
use_add_b_data = "True"
use_add_se_data = "True"
use_hydroisomer_data = "True"

# Model training parameters
[model_construct]
train_batch = 8
val_batch = 8
classes = 8
epochs = 10
learning_rate = 0.0001

# Model training class weights
[model_construct_class_weight.classes_weight]
0 = 0.00324967
1 = 0.00311315
2 = 0.00232119
3 = 0.00369775
4 = 0.00357154
5 = 0.0037113
6 = 0.00155595
7 = 0.00369361